## 1. 자료구조와 알고리즘
### 1.1. 자료구조(Data Structure)란?
- 정의: 데이터를 효율적으로 저장, 관리, 처리하기 위해 미리 정의된 데이터의 틀 또는 구조
- 비유 - 도서관
    - 나쁜 자료구조: 도서관에 새로 들어온 책을 입구부터 순서 없이 바닥에 쌓아두는 것
    - 문제점: 특정 책을 찾는 데(데이터를 탐색하는 데) 시간이 오래 걸리고, 새 책을 넣거나 기존 책을 빼기(데이터 삽입과 삭제)가 매우 비효율적
    - 좋은 자료구조: 책을 장르별로 나누고, 다시 가나다 순으로 책장에 정리하는 것
    - 장점: 어떤 책이든 빠르게 찾고, 꽂고, 뺄 수 있음
- 어떤 자료구조를 선택하느냐에 따라 프로그램의 전체 성능이 좌우됨

### 1.2. 알고리즘(Algorithm)이란?
- 정의: 어떤 문제를 해결하기 위한 명확한 절차 또는 방법
- 자료구조와의 관계
    - 자료구조=잘 정리된 재료 창고
    - 알고리즘=창고에서 재료를 꺼내 요리를 만드는 효율적인 레시피
    - 좋은 레시피(알고리즘)가 있어도 재료가 엉망(나쁜 자료구조)이면 요리가 느려짐. 반대도 마찬가지

### 1.3. 성능 분석: 복잡도(Complexity)
- 알고리즘과 자료구조의 성능을 객관적으로 평가하는 척도
- 왜 필요한가?
    - 컴퓨터 사양, 프로그래밍 언어 등의 환경적 요인에 따라 측정 시간은 매번 달라짐
    - 이러한 환경적 요인을 배제하고, "입력 데이터가 커질수록 알고리즘의 성능이 얼마나 나빠지는가?" 하는 성장률에 집중

#### 1.3.1. 시간 복잡도(Time Complexity)
- 정의: 입력 데이터의 크기(n)가 증가할 때, 알고리즘이 실행되는 데 걸리는 시간이 얼마나 증가하는가

#### 1.3.2. 공간 복잡도(Space Complexity)
- 정의: 입력 데이터의 크기($n$)가 증가할 때, 알고리즘이 사용하는 메모리 공간이 얼마나 증가하는가

#### 1.3.3. Big-O 표기법: 최악의 경우
- 복잡도를 표기하는 가장 표준적인 방법
- 의미: 아무리 운이 나빠도(최악의 경우), 이 알고리즘의 성능은 이것보다 나빠지지 않는다 라는 성능의 상한선

#### 1.3.4. Big-O 예시
| 표기법 | 명칭 (속도) | 설명 (의미) | 대표 예시 |
| :--- | :--- | :--- | :--- |
| **$O(1)$** | **상수** (매우 빠름) | 입력 데이터($n$)가 아무리 커져도 실행 시간은 일정함. | 배열의 `n`번째 요소 접근 `arr[n]` |
| **$O(\log n)$** | **로그** (빠름) | $n$이 2배가 되어도, 실행 시간은 1단계만 늘어남. | **이진 탐색 (Binary Search)** |
| **$O(n)$** | **선형** (준수함) | $n$이 2배가 되면, 실행 시간도 2배가 됨. | `for`문으로 배열 1번 순회 |
| **$O(n \log n)$** | **로그-선형** | 효율적인 정렬 알고리즘의 표준. | **병합 정렬, 퀵 정렬** |
| **$O(n^2)$** | **제곱** (느림) | $n$이 2배가 되면, 실행 시간은 4배가 됨. (비효율 시작) | 2중 `for`문 (버블 정렬) |
| **$O(2^n)$** | **지수** (매우 느림) | $n$이 조금만 커져도 사실상 사용 불가능. | 단순 재귀로 구현한 피보나치 수열 |

---

## 2. 선형 자료구조(Linear Data Structures)
- 선형 구조란 데이터가 일렬로 나열된, 마치 기차 칸처럼 순차적으로 연결된 형태
- 가장 단순하고 기본적인 자료구조

### 2.1. 배열(Array)
- 정의: 같은 타입의 데이터 여러 개를 메모리상에 연속된 공간에 저장하는 가장 기본적인 자료구조
- 핵심 특징 (인덱스): 모든 데이터에 [0], [1], [2]... 와 같은 고유한 방 번호(인덱스) 부여
- 비유: 아파트의 '101호, 102호, 103호'처럼 주소가 정해진 우편함
- 장점
    - 속도: 인덱스를 알면 어떤 데이터든 $O(1)$ (상수 시간) 만에 즉시 접근(읽기/쓰기) 가능
    - ex. `arr[100]`번에 바로 접근
- 단점
    - 크기 고정: 처음에 크기를 정하면 바꿀 수 없음(크기를 늘리려면 새 배열을 만들어 복사해야 함)
    - 삽입/삭제 비효율: 중간에 데이터를 삽입하거나 삭제하면, 그 뒤의 모든 데이터를 한 칸씩 밀거나 당겨야 함(최악 $O(n)$ )

### 2.2. 연결 리스트(Linked List)
- 정의: 배열의 크기 고정과 삽입/삭제 비효율 문제를 해결하기 위해 등장
- 핵심 특징 (노드와 포인터)
    - 노드(Node): 데이터와 다음 노드의 주소(포인터)를 한 세트로 가짐
    - 이 노드들이 징검다리처럼 다음 노드를 가리키며 연결
- 비유: 기차 칸(노드)들이 서로 연결 고리(포인터)로 이어져 있는 모습
- 장점
    - 크기 유연: 크기가 정해져 있지 않고, 새 데이터가 필요할 때마다 노드를 추가(메모리 할당)하면 됨
    - 삽입/삭제 효율: 중간에 데이터를 삽입하거나 삭제할 때, 연결 고리(포인터)만 바꿔주면 됨( $O(1)$ )
- 단점
    - 탐색 비효율: 인덱스가 없으므로, $k$번째 데이터를 찾으려면 첫 번째(Head) 노드부터 $k$번 이동해야 함 ( $O(n)$ )
    - 추가 공간: 데이터를 저장할 공간 외에, 다음 노드를 가리킬 포인터 공간이 추가로 필요
- 종류
    - 단일 연결 리스트 (Singly): 다음 노드만 가리킴(단방향)
    - 이중 연결 리스트 (Doubly): 다음 노드와 이전 노드를 모두 가리킴(양방향)

### 2.3. 스택(Stack)
- 정의: 데이터의 입/출력이 한쪽 끝(Top)에서만 일어나는 자료구조
- 핵심 원칙: LIFO (Last-In, First-Out). "마지막에 들어온 것이 가장 먼저 나간다."
- 비유: 프링글스 통
    - Push (삽입): 프링글스 통에 과자를 넣는 것 (맨 위에 쌓임)
    - Pop (삭제): 프링글스 통에서 과자를 꺼내는 것 (맨 위만 꺼낼 수 있음)
- 주요 용도: 되돌리기 기능, 함수 호출 관리(콜 스택), 괄호 검사, 브라우저 뒤로 가기

### 2.4. 큐(Queue)
- 정의: 데이터가 한쪽(Rear)에서는 삽입되고, 반대쪽(Front)에서는 삭제되는 자료구조
- 핵심 원칙: FIFO (First-In, First-Out). "먼저 들어온 것이 가장 먼저 나간다."
- 비유: 은행 창구의 대기 줄
    - Enqueue (삽입): 줄의 맨 뒤(Rear)에 서는 것
    - Dequeue (삭제): 줄의 맨 앞(Front) 사람이 서비스를 받고 나가는 것
- 주요 용도: 프린터 인쇄 대기열, 너비 우선 탐색(BFS), 캐시(Cache) 구현

| 자료구조 | 핵심 동작 | 접근/탐색 | 삽입/삭제 |
| :--- | :--- | :--- | :--- |
| 배열 | 인덱스 $O(1)$ | $O(1)$ (빠름) | $O(n)$ (느림) |
| 연결 리스트 | 포인터 연결 | $O(n)$ (느림) | $O(1)$ (빠름) |
| 스택 | LIFO (Push/Pop) | Top만 $O(1)$ | Top만 $O(1)$ |
|큐 | FIFO (En/Dequeue) | Front/Rear만 $O(1)$ | Front/Rear만 $O(1)$ |

---

## 3. 비선형 자료구조(Non-Linear Data Structures)
- 데이터가 1:1이 아닌, 1:N 또는 N:M의 관계를 가지는 복잡한 구조(ex. 부모-자식 관계, 친구 관계)

### 3.1. 트리(Tree)
- 정의: 부모-자식 관계처럼 계층적인 관계를 표현하는 자료구조(그래프의 특수한 한 종류)
- 핵심 특징
    - 루트(Root): 가장 위에 있는 최상위 노드(시작점)
    - 노드(Node): 데이터 값과 자식 노드들을 가리키는 포인터
    - 간선(Edge): 노드와 노드를 연결하는 선
    - 리프(Leaf): 자식이 없는 맨 아래의 노드
- 비유: 회사의 조직도, 족보, 컴퓨터의 폴더(디렉터리) 구조

#### 3.1.1. 이진 트리(Binary Tree)
- 모든 노드가 최대 2개의 자식 노드(왼쪽 자식, 오른쪽 자식)만을 가지는 트리

#### 3.1.2. 이진 탐색 트리(BST, Binary Search Tree)
- 이진 트리에서 탐색 성능을 극대화하기 위해 규칙을 추가한 트리
- 핵심 규칙
    - 모든 노드의 왼쪽 서브트리는 부모 노드보다 작은 값만 가짐
    - 모든 노드의 오른쪽 서브트리는 부모 노드보다 큰 값만 가짐
- 장점
    - 이 규칙 덕분에 데이터를 찾을 때, 매번 비교 대상이 절반씩 감소
    - 탐색/삽입/삭제의 평균 시간 복잡도가 $O(\log n)$
- 단점
    - 데이터가 순서대로 들어오면(ex. 1, 2, 3, 4, 5) 트리가 한쪽으로 치우쳐 연결 리스트처럼 변해 성능이 $O(n)$으로 나빠질 수 있음
- 이 단점을 해결하기 위해 스스로 균형을 잡는 트리(Balanced Tree)인 AVL 트리, Red-Black 트리 등이 등장

### 3.2. 힙(Heap)
- 정의: 우선순위 큐(Priority Queue)를 구현하기 위해 만들어진 특수한 트리 기반 자료구조
- 핵심 규칙(Heap Property)
    - 최대 힙(Max Heap): 부모 노드의 값은 항상 자식 노드의 값보다 크거나 같음(루트 = 최댓값)
    - 최소 힙(Min Heap): 부모 노드의 값은 항상 자식 노드의 값보다 작거나 같음(루트 = 최솟값)
- 특징
    - 항상 완전 이진 트리의 형태를 유지(데이터를 왼쪽부터 차곡차곡 채움)
    - 데이터 삽입/삭제(가장 큰/작은 값) 시 $O(\log n)$의 성능을 보장

### 3.3. 그래프(Graph)
- 정의: 자료구조 중 가장 복잡하고 일반적인 형태. 정점(Vertex, 노드)과 이를 연결하는 간선(Edge, 선)으로 구성된 자료구조
- 핵심 특징
    - 트리와 달리 부모-자식 계층이 없음
    - 사이클(Cycle)이 존재할 수 있음 (A -> B -> C -> A)
- 비유: 지하철 노선도 (정점=역, 간선=노선), 소셜 네트워크 (정점=사람, 간선=친구 관계), 도로망

#### 3.3.1. 그래프 표현 방식(코드 구현 시)
- 인접 행렬(Adjacency Matrix): $V \times V$ 크기의 2차원 배열
    - `matrix[i][j] = 1` (연결됨), `0` (연결 안 됨)
    - 장점: 두 정점의 연결 여부를 $O(1)$ 만에 즉시 확인
    - 단점: 정점 수($V$)가 많으면 $V^2$ 만큼의 공간이 필요해 메모리 낭비(희소 그래프에 불리)
- 인접 리스트(Adjacency List): 각 정점마다 연결된 정점들의 리스트를 저장
    - 장점: 간선의 개수($E$)만큼만 공간이 필요 $O(V+E)$(희소 그래프에 유리)
    - 단점: 두 정점의 연결 여부를 확인하려면 리스트를 탐색해야 함

#### 3.3.2. 그래프 탐색 알고리즘
- DFS(Depth-First Search, 깊이 우선 탐색)방식
    - "일단 갈 수 있는 데까지 끝까지 가본다."
    - 구현: 스택(Stack) 또는 재귀 함수 사용
    - 비유: 미로 찾기 (한쪽 길로 끝까지 가다가 막히면, 이전 갈림길로 돌아와 다른 길로 감)
- BFS(Breadth-First Search, 너비 우선 탐색)방식
    - "현재 위치에서 가장 가까운 곳부터 차례로 방문한다."
    - 구현: 큐(Queue) 사용
    - 비유: 출발지(루트)에서 친구(1촌)를 모두 방문하고, 그다음 친구의 친구(2촌)를 모두 방문(최단 경로 찾기에 자주 쓰임)

---

## 4. 해시 테이블(Hash Table)
- 정의: `Key`와 `Value`가 1:1로 매핑되는 `Key-Value` 쌍 데이터를 저장하는 자료구조
- 핵심 목표: Key를 알면, 그에 대응하는 Value를 평균 $O(1)$라는 상수 시간(매우 빠름)에 찾아내는 것
- 비유
    - 파이썬의 딕셔너리(Dictionary): `my_dict = {"apple": "사과"}`
    - 자바의 해시맵(HashMap): `Map<String, String> map = new HashMap<>();`
    - 짐 보관소
        - 내 짐(`Value`)을 맡기면, 관리자가 내 이름(`Key`)을 보고 "당신은 5번 보관함에 넣으세요"라고 알려줌(이 과정이 해시 함수)
        - 나중에 짐을 찾을 때도, 내 이름(`Key`)만 말하면 5번(`Hash`)으로 바로 가서 짐(`Value`)을 꺼내옴

### 4.1. 핵심 구성 요소
#### 4.1.1. 해시 함수(Hash Function)
- 역할: 어떤 `Key` 값이 들어오든, 이 `Key`를 특정 범위 안의 정수(숫자)로 바꿔주는 함수
- 결과값: 이 정수 값을 해시(Hash) 또는 해시 값(Hash Value)이라고 부름
- 특징
    - 일관성: 동일한 `Key`를 넣으면 항상 동일한 `Hash`가 나와야 함(ex. "apple"은 항상 5)
    - 고유성 (이상적): 서로 다른 Key는 가급적 서로 다른 `Hash`가 나와야 함(ex. hash("apple") -> 5, hash("banana") -> 2)

#### 4.1.2. 버킷(Bucket) or 슬롯(Slot)
- 역할: 해시 함수에 의해 계산된 `Hash` 값을 인덱스(index)로 사용하는 거대한 배열(Array)
- `Value`는 바로 이 버킷(배열의 칸)에 저장됨

### 4.2. 해시 테이블의 동작 원리(평균 $O(1)$ )
- 저장 (Insert): `Key`("apple")를 해시 함수에 넣어 `Hash`(5)를 얻는다. -> 5번 버킷(배열)에 `Value`("사과")를 저장한다.
- 검색 (Search): `Key`("apple")를 해시 함수에 넣어 `Hash`(5)를 얻는다. -> 5번 버킷에 가서 `Value`("사과")를 바로 꺼낸다.
- 삭제 (Delete): `Key`("apple")를 해시 함수에 넣어 `Hash`(5)를 얻는다. -> 5번 버킷의 데이터를 삭제한다.
- $O(1)$인 이유?
    - 배열(Bucket)은 인덱스를 알면 $O(1)$에 접근 가능. 해시 함수 계산 시간은 데이터 크기($n$)와 상관없이 거의 일정( $O(1)$ )하므로 $O(1) + O(1) = O(1)$

### 4.3. 문제점: 해시 충돌(Hash Collision)
- 정의: 서로 다른 `Key`를 해시 함수에 넣었는데, 같은 `Hash` 값이 나오는 상황
- 비유: 짐 보관소에서 "A"도 5번, "B"도 5번 보관함을 배정받은 상황.
- ex. `hash("apple") -> 5` 이고, `hash("melon") -> 5 `인 경우
- 충돌이 발생하면 $O(1)$의 장점이 깨지기 때문에, 이 충돌을 "잘 해결하는 것"이 해시 테이블의 핵심 기술

### 4.4. 충돌 해결 방법(Collision Resolution)
#### 4.4.1. 체이닝(Chaining) (가장 보편적인 방법)
- 방식: 버킷(배열)의 각 칸을 연결 리스트(Linked List)로 만듦
- 동작: 충돌이 발생하면, 해당 버킷(5번 칸)의 연결 리스트에 데이터를 이어서 추가
- 비유: 5번 보관함에 "A"의 짐이 이미 있으면, "B"의 짐은 그 보관함 안의 "A" 짐 옆에 둠
- 단점: 충돌이 한 곳에 몰리면(최악의 경우), 연결 리스트가 길어져 탐색 시간이 $O(n)$까지 나빠질 수 있음

#### 4.4.2. 개방 주소법(Open Addressing)
- 방식: 버킷을 연결 리스트로 만들지 않고, 비어있는 다른 버킷을 찾아 데이터를 저장
- 동작: 5번 칸이 차있으면, 정해진 규칙(ex. 바로 옆 6번, 7번...)에 따라 비어있는 다음 칸을 찾아 저장. (이를 탐사(Probing)라고 함)
- 비유: 5번 보관함이 꽉 찼으면, 6번 보관함을 열어보고 비었으면 거기에 넣음
- 단점: 데이터가 특정 위치에 몰리는 클러스터링(Clustering) 현상이 발생할 수 있음

---

## 5. 주요 알고리즘(정렬 및 탐색)
### 5.1. 탐색(Searching)
- 데이터 집합(주로 배열)에서 원하는 특정 값을 찾아내는 과정

#### 5.1.1. 선형 탐색(Linear Search)
- 방식: 배열의 첫 번째 요소부터 마지막 요소까지 하나씩 순서대로 비교하며 원하는 값을 찾음
- 비유: 교실에서 학생(데이터)을 찾는데, 맨 앞줄 첫 번째 학생부터 차례대로 "이름이 OOO 맞니?"라고 물어보는 것
- 시간 복잡도: $O(n)$
    - 최악의 경우, 찾는 값이 맨 마지막에 있거나 아예 없으면 $n$번 모두 비교해야 함

#### 5.1.2. 이진 탐색(Binary Search)
- 전제 조건: 데이터가 반드시 정렬(Sorted)되어 있어야 함
- 방식
    - 데이터 집합의 중간(Middle) 값 확인
    - 찾는 값이 중간 값보다 작으면 -> 왼쪽 절반을 탐색 대상으로 변경
    - 찾는 값이 중간 값보다 크면 -> 오른쪽 절반을 탐색 대상으로 변경
    - 이 과정을 대상이 1개가 될 때까지 반복
- 비유: 사전에서 단어 찾기
    - 1,000페이지 사전에서 "Computer"를 찾을 때, 1페이지부터 넘기지 않음(선형 탐색)
    - 일단 500페이지로 이동(중간)
    - 500페이지 단어가 "Machine"이면, "Computer"는 그보다 앞에 있으니 1~499페이지 사이(왼쪽 절반)에서 다시 중간으로 이동
- 시간 복잡도: $O(\log n)$
    - 매 탐색마다 검색 범위가 절반씩 줄어들기 때문에 $O(n)$인 선형 탐색보다 압도적으로 빠름

### 5.2. 정렬(Sorting)
- 데이터를 특정 기준(오름차순, 내림차순 등)에 맞게 순서대로 나열하는 과정

#### 5.2.1. 기본 정렬 알고리즘(직관적, $O(n^2)$ )
- $n$이 작을 때는 괜찮지만, 커지면 성능이 급격히 나빠짐(2중 `for`문 구조)

##### 5.2.1.1. 버블 정렬(Bubble Sort)
- 방식: 서로 이웃한 두 데이터를 비교하며 자리를 변경. 이 과정을 리스트 끝까지 반복(가장 크거나 작은 값이 거품처럼 맨 뒤로 밀려남)
- 비유: 줄 서있는 학생들 중, 바로 옆 친구와 키를 비교해서 키 큰 사람이 뒤로 가는 것을 계속 반복

##### 5.2.1.2. 선택 정렬(Selection Sort)
- 방식: 전체 데이터 중에서 가장 작은(혹은 큰) 값을 찾아 맨 앞 자리와 변경. 그다음, 남은 데이터 중에서 가장 작은 값을 찾아 두 번째 자리와 변경
- 비유: 줄 세울 때, 전체 학생 중 키가 가장 작은 학생을 찾아 맨 앞으로 보내고, 남은 학생 중 가장 작은 학생을 찾아 두 번째 자리에 보내는 방식

##### 5.2.1.3. 삽입 정렬(Insertion Sort)
- 방식: 두 번째 데이터부터 시작하여, 앞에 있는 정렬된 부분의 올바른 위치에 데이터를 끼워 넣음(삽입)
- 비유: 손에 든 카드를 정렬할 때, 이미 정렬된 카드들 사이의 올바른 위치에 새 카드를 끼워 넣는 방식

#### 5.2.2. 고급 정렬 알고리즘(효율적, $O(n \log n)$ )
- 분할 정복 (Divide and Conquer) 전략을 사용
- 큰 문제를 작은 문제로 쪼개서(Divide) 해결한 뒤, 나중에 합쳐서(Conquer) 전체 문제를 해결

##### 5.2.2.1. 병합 정렬(Merge Sort)
- 방식
    - (Divide) 데이터를 절반씩 계속 쪼개서 1개가 남을 때까지 분할
    - (Conquer) 나눠진 데이터들을 다시 합치면서(Merge) 정렬
- 특징: 항상 $O(n \log n)$을 보장하며, **안정 정렬(Stable Sort)**(같은 값의 순서가 유지됨)

##### 5.2.2.2. 퀵 정렬(Quick Sort)
- 방식
    - (Divide) 데이터 중 기준점(피벗(Pivot))을 하나 선정
    - 피벗보다 작은 값은 왼쪽, 큰 값은 오른쪽으로 분리(분할)
    - 분리된 왼쪽/오른쪽 그룹에 대해 이 과정을 재귀적으로 반복
- 특징: 평균 속도가 매우 빨라 이름처럼 Quick하지만, 피벗 선택이 잘못되면(최악의 경우) $O(n^2)$이 될 수 있음

| 정렬 알고리즘 | 평균 시간 복잡도 | 최악 시간 복잡도 | 공간 복잡도 | 특징 |
| :--- | :--- | :--- | :--- | :--- |
| 버블 정렬 | $O(n^2)$ | $O(n^2)$ | $O(1)$ | 구현 간단, 비효율 |
| 선택 정렬 | $O(n^2)$ | $O(n^2)$ | $O(1)$ | 교환(Swap) 횟수가 적음 |
| 삽입 정렬 | $O(n^2)$ | $O(n^2)$ | $O(1)$ | 이미 정렬된 경우 $O(n)$ |
| 병합 정렬 | $O(n \log n)$ | $O(n \log n)$ | $O(n)$ | 안정 정렬, 추가 공간 필요 |
| 퀵 정렬 | $O(n \log n)$ | $O(n^2)$ | $O(\log n)$ | 평균 속도 가장 빠름 |
