# 7주차

## 자료구조가 왜 필요할까?

100만 명의 회원 데이터에서 특정 사용자를 찾는데 1초 걸리는 것과 0.001초 걸리는 것, 뭐가 다를까요? 바로 자료구조의 차이입니다. 같은 데이터라도 어떻게 저장하고 관리하느냐에 따라 성능이 천지차이입니다.

**자료구조를 알아야 하는 이유**

- 효율적인 데이터 관리와 빠른 검색
- 메모리 최적화
- 적절한 알고리즘 선택을 위한 기초
- 실무에서 라이브러리/프레임워크 내부 동작 이해

---

## 시간 복잡도와 공간 복잡도

## Big-O 표기법이란?

알고리즘의 성능을 표현하는 방법입니다. 데이터가 n개일 때 연산이 몇 번 일어나는지를 나타내죠.

**자주 나오는 시간 복잡도**

```
O(1)       - 상수 시간: 배열 인덱스 접근
O(log n)   - 로그 시간: 이진 탐색
O(n)       - 선형 시간: 배열 순회
O(n log n) - 로그 선형: 효율적인 정렬 (병합, 퀵)
O(n²)      - 제곱 시간: 이중 for문, 버블 정렬
O(2ⁿ)      - 지수 시간: 피보나치 재귀 (최악)

```

**면접 팁**: "이 알고리즘의 시간 복잡도는?"이라는 질문이 자주 나옵니다. 특히 최선, 평균, 최악의 경우를 구분해서 설명할 수 있어야 합니다.

## 공간 복잡도

메모리를 얼마나 쓰는지를 나타냅니다. 시간과 공간은 트레이드오프 관계입니다. 메모리를 더 쓰면 속도를 높일 수 있고(캐싱), 속도를 포기하면 메모리를 절약할 수 있습니다.

---

## 배열 (Array)

## 배열의 특징

**장점**

- 인덱스로 O(1)에 접근 가능
- 메모리 상에서 연속적으로 배치되어 캐시 효율 좋음
- 구현이 간단

**단점**

- 크기가 고정됨 (동적 배열로 해결 가능)
- 삽입/삭제 시 O(n) - 뒤의 원소들을 이동해야 함
- 메모리 낭비 가능성

```java
// 중간 삽입이 비효율적인 이유
int[] arr = {1, 2, 3, 4, 5};
// 인덱스 2에 10 삽입하려면
// 3, 4, 5를 한 칸씩 뒤로 밀어야 함

```

**면접 포인트**: "배열과 리스트의 차이는?" - 가장 기본적이면서 자주 나오는 질문입니다.

---

## 연결 리스트 (Linked List)

## 연결 리스트의 구조

각 노드가 데이터와 다음 노드의 주소를 가지고 있습니다. 메모리 상에서 흩어져 있어도 됩니다.

```java
class Node {
    int data;
    Node next;
}

```

## 배열 vs 연결 리스트

| 연산 | 배열 | 연결 리스트 |
| --- | --- | --- |
| 접근 | O(1) | O(n) |
| 삽입/삭제 (앞) | O(n) | O(1) |
| 삽입/삭제 (중간) | O(n) | O(1)* |
| 메모리 | 연속적 | 분산적 |
- 중간 삽입/삭제도 해당 위치까지 가는 건 O(n)이지만, 삽입/삭제 자체는 O(1)

## 종류

**단일 연결 리스트**: 한 방향으로만 이동
**이중 연결 리스트**: 양방향 이동 가능 (prev, next)
**원형 연결 리스트**: 마지막 노드가 첫 노드를 가리킴

**실무 사용 예시**

- LRU 캐시 구현 (이중 연결 리스트 + 해시맵)
- 브라우저 뒤로/앞으로 가기
- 음악 플레이어 재생 목록

---

## 스택 (Stack)

## LIFO (Last In First Out)

나중에 들어온 게 먼저 나갑니다. 접시 쌓기를 생각하면 됩니다.

**핵심 연산**

```java
push(x)  // 삽입 - O(1)
pop()    // 삭제 및 반환 - O(1)
peek()   // 최상단 확인 - O(1)
isEmpty()

```

**실무 활용**

- 함수 호출 스택 (재귀)
- 괄호 검사
- 브라우저 방문 기록 (뒤로 가기)
- 실행 취소 (Undo)
- DFS 구현

**면접 단골 문제**

```
유효한 괄호 검사: "(())" → true, "(()" → false
후위 표기법 계산: "23+5*" → (2+3)*5 = 25

```

---

## 큐 (Queue)

## FIFO (First In First Out)

먼저 들어온 게 먼저 나갑니다. 줄 서기를 생각하면 됩니다.

**핵심 연산**

```java
enqueue(x)  // 삽입 - O(1)
dequeue()   // 삭제 및 반환 - O(1)
peek()      // 맨 앞 확인 - O(1)

```

## 큐 종류

**일반 큐**: 기본 FIFO
**원형 큐**: 배열로 구현 시 공간 재사용
**우선순위 큐**: 우선순위가 높은 게 먼저 나옴 (힙으로 구현)
**덱(Deque)**: 양쪽에서 삽입/삭제 가능

**실무 활용**

- 작업 스케줄링
- 메시지 큐 (Kafka, RabbitMQ)
- BFS 구현
- 프린터 대기열
- 캐시 구현 (LRU)

---

## 해시 테이블 (Hash Table)

## 해시 테이블이 왜 강력할까?

검색, 삽입, 삭제가 평균 O(1)입니다. 엄청 빠르죠.

## 동작 원리

1. 키를 해시 함수에 넣어서 해시값(인덱스) 생성
2. 해당 인덱스에 값 저장
3. 검색 시 같은 해시 함수로 바로 찾아감

```java
hash("kim") = 3 → arr[3]에 저장
hash("lee") = 7 → arr[7]에 저장

```

## 해시 충돌 (Collision)

서로 다른 키가 같은 해시값을 가질 때 발생합니다.

**해결 방법**

**체이닝 (Chaining)**

- 같은 인덱스에 연결 리스트로 여러 값 저장
- Java HashMap의 기본 방식
- 충돌 많으면 O(n)까지 느려짐

**오픈 어드레싱 (Open Addressing)**

- 충돌 나면 다른 빈 공간 찾음
- 선형 탐사, 이차 탐사, 이중 해싱 등

**면접 핵심**: Java 8 이후 HashMap은 체이닝 시 일정 개수 이상이면 연결 리스트를 트리로 변환해서 O(log n)을 보장합니다.

## 로드 팩터 (Load Factor)

```
로드 팩터 = 저장된 데이터 개수 / 해시 테이블 크기

```

Java HashMap은 0.75를 기본값으로 사용합니다. 이 값을 넘으면 테이블 크기를 2배로 늘립니다(리해싱).

**실무 활용**

- 데이터베이스 인덱스
- 캐시 구현
- 중복 체크
- 빠른 조회가 필요한 모든 곳

---

## 트리 (Tree)

## 트리 기본 개념

**용어 정리**

- **노드(Node)**: 데이터를 저장하는 단위
- **루트(Root)**: 최상위 노드
- **리프(Leaf)**: 자식이 없는 노드
- **높이(Height)**: 루트부터 가장 깊은 리프까지의 거리
- **깊이(Depth)**: 루트부터 해당 노드까지의 거리

## 이진 트리 (Binary Tree)

각 노드가 최대 2개의 자식을 가집니다.

**종류**

**완전 이진 트리**: 마지막 레벨 제외하고 모두 채워짐, 마지막 레벨은 왼쪽부터 채워짐
**포화 이진 트리**: 모든 레벨이 꽉 참
**편향 트리**: 한쪽으로만 치우침 (최악의 경우)

## 이진 탐색 트리 (BST)

**규칙**: 왼쪽 자식 < 부모 < 오른쪽 자식

**시간 복잡도**

- 균형 잡힌 경우: O(log n)
- 편향된 경우: O(n) - 연결 리스트처럼 됨

```
    5
   / \
  3   7
 / \   \
1   4   9

```

3 검색: 5 → 3 (2번 비교)
9 검색: 5 → 7 → 9 (3번 비교)

**면접 포인트**: "BST가 편향되면 어떻게 해결하나요?" → AVL Tree, Red-Black Tree

## AVL 트리

자가 균형 이진 탐색 트리입니다. 모든 노드의 왼쪽/오른쪽 서브트리 높이 차이가 최대 1입니다.

**회전(Rotation)으로 균형 유지**

- LL, RR, LR, RL 회전
- 삽입/삭제 후 자동으로 균형 맞춤
- 모든 연산이 O(log n) 보장

## Red-Black 트리

**규칙**

1. 모든 노드는 Red 또는 Black
2. 루트는 Black
3. 리프(NIL)는 Black
4. Red 노드의 자식은 Black
5. 루트부터 리프까지 모든 경로의 Black 노드 수는 같음

AVL보다 덜 엄격하게 균형을 맞춰서 삽입/삭제가 더 빠릅니다. Java TreeMap/TreeSet이 이걸 사용합니다.

**AVL vs Red-Black**

- AVL: 더 엄격한 균형, 검색 빠름
- Red-Black: 삽입/삭제 빠름, 실무에서 더 많이 사용

## 트리 순회

**전위 순회 (Pre-order)**: 부모 → 왼쪽 → 오른쪽
**중위 순회 (In-order)**: 왼쪽 → 부모 → 오른쪽 (BST에서 오름차순 정렬)
**후위 순회 (Post-order)**: 왼쪽 → 오른쪽 → 부모
**레벨 순회 (Level-order)**: BFS로 레벨별 순회

```java
// 중위 순회 - 재귀
void inorder(Node node) {
    if (node == null) return;
    inorder(node.left);
    System.out.println(node.data);
    inorder(node.right);
}

```

---

## 힙 (Heap)

## 힙의 특징

완전 이진 트리 형태로, 우선순위 큐를 구현하는 데 사용됩니다.

**최대 힙**: 부모 ≥ 자식
**최소 힙**: 부모 ≤ 자식

**시간 복잡도**

- 삽입: O(log n)
- 삭제(루트): O(log n)
- 최대/최소값 확인: O(1)

## 힙 연산

**삽입**

1. 가장 마지막에 추가
2. 부모와 비교하며 위로 올림 (Heapify Up)

**삭제 (루트 제거)**

1. 루트를 제거하고 마지막 노드를 루트로
2. 자식과 비교하며 아래로 내림 (Heapify Down)

**배열로 구현**

```
인덱스 i의 노드
- 왼쪽 자식: 2*i + 1
- 오른쪽 자식: 2*i + 2
- 부모: (i-1) / 2

```

**실무 활용**

- 우선순위 큐 (Java PriorityQueue)
- 힙 정렬
- 운영체제 작업 스케줄링
- 다익스트라 알고리즘

**면접 문제**: "K번째로 큰 원소 찾기" → 최소 힙 사용

---

## 그래프 (Graph)

## 그래프 기본

노드(정점)와 간선(엣지)로 이루어진 구조입니다. 트리보다 일반화된 개념이죠.

**종류**

**방향 그래프**: 간선에 방향이 있음 (A → B)
**무방향 그래프**: 간선에 방향 없음 (A — B)
**가중치 그래프**: 간선에 비용/거리가 있음
**순환 그래프**: 사이클 존재
**비순환 그래프**: 사이클 없음 (DAG)

## 그래프 표현 방법

**인접 행렬 (Adjacency Matrix)**

```java
int[][] graph = new int[V][V];
graph[i][j] = 1; // i에서 j로 가는 간선 존재

```

- 공간: O(V²)
- 간선 확인: O(1)
- 모든 간선 순회: O(V²)

**인접 리스트 (Adjacency List)**

```java
List<List<Integer>> graph = new ArrayList<>();
graph.get(i).add(j); // i의 인접 노드 j 추가

```

- 공간: O(V + E)
- 간선 확인: O(degree)
- 모든 간선 순회: O(V + E)

**언제 뭘 쓸까?**

- 간선이 적으면(희소 그래프): 인접 리스트
- 간선이 많으면(밀집 그래프): 인접 행렬

## DFS (깊이 우선 탐색)

한 방향으로 끝까지 간 다음 돌아옵니다. **스택** 또는 **재귀**로 구현합니다.

```java
void dfs(int node, boolean[] visited, List<List<Integer>> graph) {
    visited[node] = true;
    for (int next : graph.get(node)) {
        if (!visited[next]) {
            dfs(next, visited, graph);
        }
    }
}

```

**시간 복잡도**: O(V + E)

**활용**

- 경로 찾기
- 사이클 탐지
- 위상 정렬

## BFS (너비 우선 탐색)

가까운 노드부터 탐색합니다. **큐**로 구현합니다.

```java
void bfs(int start, List<List<Integer>> graph) {
    Queue<Integer> queue = new LinkedList<>();
    boolean[] visited = new boolean[V];

    queue.offer(start);
    visited[start] = true;

    while (!queue.isEmpty()) {
        int node = queue.poll();
        for (int next : graph.get(node)) {
            if (!visited[next]) {
                queue.offer(next);
                visited[next] = true;
            }
        }
    }
}

```

**시간 복잡도**: O(V + E)

**활용**

- 최단 경로 (가중치 없을 때)
- 레벨별 탐색

**면접 핵심**: "DFS와 BFS의 차이와 각각 언제 사용하나요?"

---

## 정렬 알고리즘

## 버블 정렬 (Bubble Sort)

인접한 원소끼리 비교해서 큰 걸 뒤로 보냅니다.

**시간 복잡도**: O(n²)
**공간 복잡도**: O(1)
**안정 정렬**: Yes

실무에서는 안 씁니다. 느려요.

## 선택 정렬 (Selection Sort)

최소값을 찾아서 맨 앞과 교환합니다.

**시간 복잡도**: O(n²)
**공간 복잡도**: O(1)
**안정 정렬**: No

## 삽입 정렬 (Insertion Sort)

적절한 위치에 삽입하며 정렬합니다.

**시간 복잡도**: O(n²), 거의 정렬된 경우 O(n)
**공간 복잡도**: O(1)
**안정 정렬**: Yes

거의 정렬된 데이터에는 빠릅니다.

## 병합 정렬 (Merge Sort)

분할 정복으로 나눠서 정렬 후 합칩니다.

**시간 복잡도**: O(n log n) - 항상 보장
**공간 복잡도**: O(n)
**안정 정렬**: Yes

```java
void mergeSort(int[] arr, int left, int right) {
    if (left < right) {
        int mid = (left + right) / 2;
        mergeSort(arr, left, mid);
        mergeSort(arr, mid + 1, right);
        merge(arr, left, mid, right);
    }
}

```

## 퀵 정렬 (Quick Sort)

피벗을 기준으로 작은 건 왼쪽, 큰 건 오른쪽으로 분할합니다.

**시간 복잡도**

- 평균: O(n log n)
- 최악: O(n²) - 피벗이 항상 최소/최대값

**공간 복잡도**: O(log n)
**안정 정렬**: No

실무에서 가장 많이 사용됩니다. 평균적으로 가장 빠릅니다.

## 힙 정렬 (Heap Sort)

힙을 만들어서 하나씩 꺼냅니다.

**시간 복잡도**: O(n log n) - 항상 보장
**공간 복잡도**: O(1)
**안정 정렬**: No

## 계수 정렬 (Counting Sort)

값의 개수를 세서 정렬합니다. 정수 정렬에 유리합니다.

**시간 복잡도**: O(n + k) - k는 최대값
**공간 복잡도**: O(k)
**안정 정렬**: Yes

범위가 작을 때 O(n)으로 정렬 가능합니다.

**정렬 알고리즘 선택 가이드**

- 작은 데이터: 삽입 정렬
- 안정 정렬 필요: 병합 정렬
- 평균 성능 중요: 퀵 정렬
- 최악 성능 보장: 병합 정렬, 힙 정렬
- 범위 제한된 정수: 계수 정렬

**면접 단골**: "Java Collections.sort()는 뭘 쓰나요?" → Timsort (병합 + 삽입)

---

## 탐색 알고리즘

## 선형 탐색 (Linear Search)

처음부터 끝까지 하나씩 확인합니다.

**시간 복잡도**: O(n)

## 이진 탐색 (Binary Search)

**전제 조건**: 정렬된 데이터

중간값과 비교해서 범위를 절반씩 줄입니다.

```java
int binarySearch(int[] arr, int target) {
    int left = 0, right = arr.length - 1;

    while (left <= right) {
        int mid = left + (right - left) / 2;

        if (arr[mid] == target) return mid;
        else if (arr[mid] < target) left = mid + 1;
        else right = mid - 1;
    }
    return -1;
}

```

**시간 복잡도**: O(log n)

**면접 변형 문제**

- 회전된 배열에서 특정 원소 찾기
- 중복된 원소의 첫 번째/마지막 인덱스 찾기

---

## 동적 계획법 (Dynamic Programming)

## DP란?

큰 문제를 작은 문제로 나누고, 작은 문제의 결과를 저장해서 재사용합니다.

**핵심 조건**

1. **최적 부분 구조**: 작은 문제의 최적 해로 큰 문제 해결
2. **중복되는 부분 문제**: 같은 계산을 반복

## 피보나치 예시

**재귀 (느림): O(2ⁿ)**

```java
int fib(int n) {
    if (n <= 1) return n;
    return fib(n-1) + fib(n-2); // 중복 계산 엄청 많음
}

```

**DP (빠름): O(n)**

```java
int fib(int n) {
    int[] dp = new int[n + 1];
    dp[0] = 0;
    dp[1] = 1;
    for (int i = 2; i <= n; i++) {
        dp[i] = dp[i-1] + dp[i-2];
    }
    return dp[n];
}

```

## Top-down vs Bottom-up

**Top-down (메모이제이션)**

- 재귀 + 캐싱
- 필요한 것만 계산

**Bottom-up (타뷸레이션)**

- 반복문
- 모든 경우 계산
- 재귀 오버헤드 없음

**면접 단골 문제**

- 배낭 문제 (Knapsack)
- 최장 공통 부분 수열 (LCS)
- 최장 증가 부분 수열 (LIS)
- 동전 거스름돈

---

## 탐욕 알고리즘 (Greedy)

## Greedy란?

매 순간 최선의 선택을 합니다. 항상 최적해를 보장하진 않지만, 보장되는 문제에서는 DP보다 빠릅니다.

**활용 예시**

- 거스름돈 (동전 개수 최소화)
- 활동 선택 문제
- 최소 신장 트리 (Kruskal, Prim)
- 다익스트라 최단 경로

**DP vs Greedy**

- DP: 모든 경우를 고려
- Greedy: 현재 최선만 선택

---

## 실무 적용 팁

## 자료구조 선택 가이드

**빠른 조회 필요**: HashMap (O(1))
**정렬된 상태 유지**: TreeMap (O(log n))
**순서 유지**: LinkedHashMap, ArrayList
**중복 제거**: HashSet, TreeSet
**양쪽 삽입/삭제**: Deque
**우선순위**: PriorityQueue (Heap)

## Spring Boot에서 자주 쓰는 곳

**Redis (해시 테이블)**

- 캐싱, 세션 관리

**데이터베이스 인덱스 (B+Tree)**

- 빠른 검색

**메시지 큐 (큐)**

- Kafka, RabbitMQ

**LRU 캐시 (이중 연결 리스트 + 해시맵)**

- 캐시 관리