## 1. 메모리 시스템

### 1.1. 메모리란 무엇인가?
: CPU가 실행할 프로그램을 저장하는 곳

#### 주기억장치(Main Memory Unit)
- RAM(휘발성)과 ROM(비휘발성)으로 구성
- 일반적으로 메모리 라고 말하면 RAM을 지칭

#### 보조기억장치(Auxiliary Memory Unit)
- 하드디스크, USB, CD-ROM 등
- ROM과 함께 전원이 차단되어도 데이터를 저장하는 기억장치

#### 캐시 메모리(Cache Memory)
- 주기억장치와 CPU 사이에 위치한 휘발성 메모리
- 주기억장치에서 실행할 프로그램의 일부분을 꺼내와서 CPU의 사용 직전에 보관하는 장소
- 자주 사용되는 코드, 데이터 등 저장

#### 레지스터(Register)
- CPU의 연산에 사용되는 휘발성 메모리
- 용량이 가장 작지만 속도는 가장 빠름

### 1.2. 메모리 계층 구조
- 상황에 맞게 여러 저장 장치를 각각 사용할 수 있도록 하여 저렴하고 성능 좋은 컴퓨터를 구현하는 설계

<img width="500" height="342" alt="image" src="https://github.com/user-attachments/assets/d5611a5d-e94b-4c72-a2c0-788546dc34a3" />


#### 메모리 계층 구조의 필요성
- 사용자 입장에서는 빠른 속도와 큰 용량을 선호
- 속도를 높이면 레지스터처럼 용량이 부족
- 용량을 높이면 하드디스크처럼 속도가 감소
- 성능을 위해 속도와 용량의 상호보완을 위해 고안한 방법이 바로 메모리 계층 구조

#### 참조 지역성
- 자주 쓰이는 데이터는 반복해서 쓰인다
- 자주 쓰이지 않는 데이터는 계속해서 자주 쓰이지 않는다
- 자주 쓰일 것 같은 데이터는 메모리에 캐시로 읽어와, 메모리까지 가지 않고 한동안 캐시에서 해결이 가능하므로 시간 단축 가능
- 자주 쓰이는 데이터는 전체 데이터 양에 비해 작은 양이기 때문에, 캐시의 용량은 메모리보다 작아도 됨
- 즉, 메모리 계층 구조의 아이디어는 프로세스가 필요로 하는 데이터를 최대한 가까운 곳에 위치시켜 속도를 향상시키는 것

### 1.3. 캐시 메모리
- 빠른 속도의 CPU가 일을 처리하고 다음 데이터를 요청했을 때, 메인 메모리에서 데이터가 도착하기까지 CPU가 놀게 되는 시간 발생
- 이 속도 차이(병목 현상)가 시스템 전체의 성능을 저하시키는 주된 원인
- 캐시 메모리는 이 문제를 해결하기 위해 등장
- CPU와 메인 메모리 사이에 위치하는, 용량은 작지만 메인 메모리보다 훨씬 빠른 특수 메모리
- CPU: 일하는 사람
- 캐시 메모리: 개인 책상(작지만 필요한 도구가 손 닿는 곳에 있음)
- 메인 메모리: 거대한 도서관(크지만 원하는 책을 찾기까지 시간이 걸림)

#### 1.3.1. 지역성의 원리
- 캐시는 CPU가 앞으로 어떤 데이터를 필요로 할지를 높은 확률로 예측하여 미리 가져다 놓는 방식으로 동작
- 지역성의 원리는 예측의 근거

##### 시간적 지역성(Temporal Locality)
- "최근에 사용된 데이터는 가까운 미래에 다시 사용될 가능성이 높다"
- 예시: 반복문 안에서 사용되는 변수 `i`나 합을 저장하는 변수 `sum`은 루프가 도는 동안 계속해서 접근하고 재사용됨
- 캐시의 동작: CPU가 변수 `sum`에 한 번 접근하면, 캐시는 해당 데이터를 방금 사용했으니 곧 또 사용하겠지라고 예측하고 `sum`의 값을 캐시 메모리에 올려둠. 이후 CPU가 `sum`을 다시 찾을 때, 메인 메모리까지 갈 필요 없이 바로 앞의 캐시에서 데이터를 가져오므로 속도가 매우 빠름

##### 공간적 지역성(Spatial Locality)
- "최근에 접근한 데이터의 주변에 있는 데이터는 곧 사용될 가능성이 높다"
- 예시: 배열의 모든 요소를 순차적으로 순회하는 코드에서 `arr[0]`에 접근했다면, 높은 확률로 곧이어 `arr[1]`, `arr[2]`에 접근할 것
- 캐시의 동작: CPU가 `arr[0]`의 데이터를 메인 메모리에 요청하면, 캐시는 `arr[0]` 뿐만 아니라 `arr[1]`, `arr[2]`, ... 등의 주변 데이터를 함께 캐시 메모리에 미리 올려놓음. 덕분에 CPU가 다음 요소들을 요청할 때는 이미 캐시에 준비되어 있어 매우 빠르게 처리 가능

#### 1.3.2. 캐시 히트(Cache Hit)와 캐시 미스(Cache Miss)
- 캐시 히트(Cache Hit): CPU가 원하는 데이터가 캐시에 이미 존재하는 경우. "예측 성공"
- 캐시 미스(Cache Miss): CPU가 원하는 데이터가 캐시에 없어 결국 메인 메모리까지 가야 하는 경우. "예측 실패", 지연 시간 발생.

### 1.4. 가상 메모리
- 과거에는 프로그램(프로세스)이 실행될 때, 프로그램의 모든 부분이 실제 물리 메모리에 통째로 올라가야 했음
- 메모리 용량 한계: 메인 메모리 크기보다 더 큰 프로그램은 실행조차 불가능
- 메모리 충돌: 여러 프로그램을 동시에 실행할 때, 한 프로그램이 다른 프로그램의 메모리 영역을 침범하여 시스템 전체가 다운되는 상황 발생
- 가상 메모리는 이러한 문제들을 해결하기 위해 운영체제가 각 프로세스에게 제공하는 가상의 메모리 공간
- 각 프로세스마다 독립적으로 주어지는 거대한 크기의 개인 공간
- 실제로는 존재하지 않지만 프로세스는 마치 이 공간 전체를 혼자 쓰는 것처럼 착각하고 실제 메모리 주소를 신경 쓸 필요 없이 자신만의 가상 주소 위에서 자유롭게 동작

#### 1.4.1. 페이징(Paging)
- 운영체제는 가상 메모리와 물리 메모리를 페이지와 프레임이라는 고정된 크기의 조각으로 나눔
- 요구 페이징: 실행에 필요한 최소한의 페이지만 물리 메모리의 비어있는 프레임에 올려놓는 것
- 주소 변환: 프로세스가 특정 가상 주소에 접근하려고 하면, MMU(Memory Management Unit)라는 장치가 페이지 테이블을 참조하여 해당 가상 주소를 실제 물리 주소로 변환해줌

---

## 2. 입출력 시스템

### 2.1. 입출력 시스템 구성 요소
입출력 시스템은 크게 물리적인 하드웨어와 이를 제어하는 소프트웨어의 조합으로 이루어짐
- 입출력 장치(I/O Devices)
    - 컴퓨터 외부에 연결되어 데이터의 입출력을 담당하는 모든 물리적인 하드웨어 장치
    - 사용자의 컴퓨터, 또는 컴퓨터와 다른 기기 간의 인터페이스 역할
- 장치 컨트롤러(Device Controller)
    - 각 입출력 장치에 부착되어 있거나 메인보드에 포함된, 장치를 직접적으로 제어하는 작은 프로세서와 같은 전자 회로(하드웨어)
    - CPU의 고급 언어와 입출력 장치의 기계어 사이를 번역하고 중재하는 하드웨어 통역가
- 장치 드라이버(Device Driver)
    - 장치 컨트롤러(하드웨어)를 제어하기 위해 만들어진 소프트웨어
    - 운영체제와 장치 컨트롤러 사이의 소프트웨어 통역가 역할
- 시스템 버스(System Bus)
    - CPU, 메모리, 장치 컨트롤러들 사이에서 데이터, 주소, 제어 신호를 실어 나르는 전기적인 통로
    - 컴퓨터의 모든 구성 요소가 서로 데이터를 주고받을 수 있게 하는 고속도로 역할. 버스의 성능이 전체 시스템의 입출력 성능에 큰 영향을 미침

### 2.2. 데이터 전송 방식

#### 프로그램 입출력
- 폴링(Polling): CPU가 모든 것을 직접 확인하고 데이터를 옮김
- 동작 과정
    - CPU가 입출력 컨트롤러에게 데이터를 준비하라는 명령을 보냄
    - CPU는 다른 일을 전혀 하지 못하고, 입출력 장치의 상태 레지스터를 무한 루프를 돌며 계속 확인(Busy Waiting)
    - 장치가 데이터를 준비 완료하면, 상태 레지스터에 준비 완료 표시
    - CPU는 이 표시를 확인한 후 데이터를 직접 옮김
- 장점: 구현이 매우 간단
- 단점: CPU가 기다리는 동안 아무 일도 못 하므로 CPU 자원이 극심하게 낭비됨. 현대적인 컴퓨터에서는 거의 사용되지 않음

#### 인터럽트 기반 입출력
- 인터럽트(Interrupt): 입출력 장치가 일이 끝나면 CPU에게 알려주는 방식
- 동작 과정
    - CPU가 입출력 컨트롤러에게 명령을 보냄
    - CPU는 입출력을 기다리지 않고 즉시 다른 프로세스나 스레드의 작업을 실행
    - 입출력 장치가 데이터 준비를 완료하면, CPU에게 인터럽트 신호를 보냄
    - CPU는 현재 하던 일을 잠시 멈추고, 인터럽트 서비스 루틴(ISR)이라는 정해진 코드 실행
    - ISR 코드 내에서 CPU가 직접 데이터를 컨트롤러에서 메모리로 옮김
    - 데이터 전송이 완료되면, 멈췄던 원래 작업으로 복귀
- 장점: 폴링 방식에 비해 CPU 낭비 감소
- 단점: CPU가 데이터 전송 자체에 직접 관여. 대용량 데이터 전송 시 잦은 인터럽트 발생은 CPU에게 상당한 부담이 될 수 있음.

#### 직접 메모리 접근(DMA)
- DMA 컨트롤러라는 전문가에게 데이터 전송을 완전히 위임
- 동작 과정
    - CPU는 DMA 컨트롤러에게 명령을 보냄. 이 명령에는 입출력 장치의 주소, 데이터를 옮길 메모리의 시작 주소, 전송할 데이터의 크기 등이 포함됨
    - CPU는 명령을 내린 후 즉시 다른 작업을 실행
    - DMA 컨트롤러가 CPU 대신 시스템 버스의 제어권을 얻어, 입출력 장치와 메모리 사이에서 데이터를 직접 빠르게 전송
    - 데이터 전송이 모두 완료되면 DMA 컨트롤러가 CPU에게 인터럽트를 딱 한 번만 보냄
    - CPU는 작업 완료 보고를 받고 다음 명령을 처리
- 장점: CPU가 본인의 작업에만 집중할 수 있어 시스템 전체의 성능과 처리량이 극대화됨
- 단점: DMA 컨트롤러라는 별도의 하드웨어 필요

### 2.3. 버스와 인터페이스

#### 2.3.1. 버스(Bus): 컴퓨터의 데이터 고속도로
- 컴퓨터 내부의 여러 구성 요소(CPU, 메모리 등)를 연결하여 데이터와 신호가 오고 갈 수 있도록 하는 공용 통신 경로

##### 주소 버스(Address Bus)
- CPU가 메모리의 특정 위치나 특정 입출력 장치를 선택하기 위해 사용하는 통로
- 단방향성: 주소 정보는 항상 CPU에서 나와 메모리나 입출력 장치로 향함
- 메모리 용량 결정: 주소 버스의 폭(bit 수)이 CPU가 접근할 수 있는 최대 메모리 공간을 결정함. ex. 32비트 주소 버스는 2^32개(약 4GB)의 주소를 표현 가능

##### 데이터 버스(Data Bus)
- CPU, 메모리, 입출력 장치 간에 실제 데이터가 오고 가는 통로
- 양방향성: 데이터는 읽기와 쓰기가 모두 가능하므로 양방향으로 움직임
- 성능에 직결: 데이터 버스의 폭은 한 번에 전송할 수 있는 데이터의 양을 결정하므로 시스템 성능에 큰 영향을 줌

##### 제어 버스(Control Bus)
- 주소와 데이터 버스를 제어하고, 모든 장치의 동작을 조율하고 통제하기 위한 신호들이 오고 가는 통로
- 다양한 제어 신호: 메모리 읽기/쓰기 신호, 인터럽트 요청 신호 등 다양한 종류의 제어 신호가 전송됨

##### 현대의 버스 구조
- 초기 컴퓨터는 모든 장치가 하나의 버스를 공유했지만 이는 심각한 병목 현상을 유발함
- 현대 컴퓨터는 빠른 장치와 느린 장치를 분리하기 위해 계층적 버스 구조를 사용 ex. CPU와 메모리를 잇는 고속의 시스템 버스, 주변 장치를 잇는 저속의 입출력 버스

#### 2.3.2. 인터페이스(Interface): 표준화된 연결 통로
- 인터페이스는 버스에 장치를 연결하기 위한 규격화된 접점
- 장치와 버스 사이에서 둘의 차이점을 흡수하고 원활한 통신을 가능하게 하는 역할

##### 인터페이스의 역할
- 표준화: 수많은 종류의 하드디스크와 키보드를 모두 컴퓨터에 연결할 수 있는 이유는 SATA, USB와 같은 표준 인터페이스를 따르기 때문. 제조사와 상관 없이 이 규격만 맞추면 버스에 연결할 수 있음

- 속도 차이 극복: 버스의 속도와 입출력 장치의 동작 속도는 크게 다르기에, 인터페이스(내부의 컨트롤러)는 버퍼(Buffer)라는 임시 저장 공간을 이용해 이 속도 차이를 완충하는 역할을 함

- 데이터 형식 변환: 장치가 사용하는 데이터 형식이나 신호 레벨이 버스에서 요구하는 것과 다를 경우, 인터페이스가 이를 변환해주는 역할도 수행.

---

## 3. 파이프라이닝

### 3.1. 파이프라이팅(Pipelining): 명령어 처리의 컨베이어 벨트 시스템
- 컴퓨터 CPU가 하나의 명령어를 처리하기 위해서는 마치 공장에서 제품 하나를 만드는 것과 같이 여러 단계를 거침

##### 파이프라이닝이 없을 때 (비유: 수공업 장인)
- 장인 한 명이 제품 A의 '설계 → 재단 → 조립 → 포장' 전 과정을 모두 끝내야만 다음 제품 B의 설계를 시작 
- 4단계짜리 작업을 3개 하려면 총 12번의 작업 시간 소요

##### 파이프라이닝 적용 (비유: 공장 컨베이어 벨트)
- 작업을 '설계', '재단', '조립', '포장'의 4개 공정으로 나누고, 각 공정마다 작업자 한 명씩을 배치
- 첫 번째 제품(A)이 설계 단계를 마치고 재단으로 넘어가면, 설계 작업자는 즉시 두 번째 제품(B)의 설계를 시작
- A가 조립으로, B가 재단으로 넘어가면, 설계 작업자는 세 번째 제품(C)의 설계를 시작
- 이런 식으로 컨베이어 벨트가 꽉 차게 되면, 그 이후부터는 1단계의 시간이 지날 때마다 제품 하나씩이 계속 완성되어 나옴

- 이처럼 파이프라이닝은 CPU에서 명령어 처리 과정을 여러 단계로 나누고, 각 단계를 별도의 하드웨어가 처리하도록 하여 여러 명령어를 동시에 겹쳐서 처리하는 기술

#### 3.1.1. CPU 명령어 처리의 일반적인 5단계 파이프라인
- IF (Instruction Fetch): 메모리에서 다음 실행할 명령어를 가져온다.
- ID (Instruction Decode): 명령어를 해석하고, 필요한 레지스터를 읽는다.
- EX (Execute): 실제 연산을 수행한다. (ALU 사용)
- MEM (Memory Access): 메모리에 데이터를 읽거나 쓴다.
- WB (Write Back): 연산 결과를 레지스터에 저장한다.

파이프라이닝을 통해 이상적인 상황에서는 1 클럭 사이클마다 1개의 명령어를 완료시킬 수 있게 되어, CPU의 명령어 처리량(Throughput)이 획기적으로 향상됨


### 3.2. 파이프라인 해저드(Pipeline Hazard): 컨베이어 벨트를 멈추게 하는 문제들
파이프라인이 항상 이상적으로 동작하지 않음. 컨베이어 벨트가 멈추거나, 순서가 꼬이거나, 잘못된 부품이 들어오는 것처럼 파이프라인의 흐름을 방해하는 문제들이 발생하는데, 이를 파이프라인 해저드라 지칭. 해저드가 발생하면 CPU는 파이프라인을 잠시 멈춰야(이를 파이프라인 스톨(Stall) 또는 버블(Bubble)이라고 함) 하므로 성능 저하가 발생.

#### 3.2.1. 구조적 해저드 (Structural Hazard)
- 원인: 서로 다른 명령어가 파이프라인의 같은 단계에서 동시에 동일한 하드웨어 자원을 사용하려고 할 때 발생
- 비유: 컨베이어 벨트의 '조립'과 '포장' 단계에서 모두 '접착제'라는 동일한 도구를 사용해야 하는데, 접착제가 하나뿐인 상황. 조립 단계에서 접착제를 쓰고 있으면, 포장 단계는 기다려야 함
- 해결책: 자원을 추가로 생성. (예: 메모리를 명령어용과 데이터용으로 분리 - 하버드 아키텍처) 현대 CPU는 설계 단계에서 이런 문제를 대부분 해결하여 거의 발생하지 않음

#### 3.2.2. 데이터 해저드 (Data Hazard)
- 원인: 앞선 명령어의 실행 결과가, 뒤따르는 명령어의 입력 값으로 필요할 때 발생. 아직 계산이 끝나지 않았는데 그 결과값을 사용하려는 경우.
- 비유: '반죽하기' 공정이 끝나야 그 반죽으로 '빵 굽기'를 할 수 있는데, 아직 반죽이 끝나지 않은 상태에서 빵 굽기 공정이 시작되려고 하는 상황.
- 예시 코드
```
ADD R1, R2, R3  // R1 = R2 + R3
SUB R4, R1, R5  // R4 = R1 - R5
```
`ADD` 명령의 결과(`R1`)가 `WB` 단계에서 `R1` 레지스터에 쓰이기 전까지, 뒤따르는 `SUB` 명령은 `ID` 단계에서 올바른 `R1` 값을 읽을 수 없음
- 해결책: 
    - 파이프라인 스톨 (Stall): 가장 간단한 방법. ADD 명령이 WB 단계까지 진행될 동안 SUB 명령의 진행을 중지. 하지만 성능 저하가 큼
    - 전방 전달 (Forwarding/Bypassing): (가장 중요하고 일반적인 해결책) ADD의 연산 결과가 EX 단계에서 나오자마자, 이 값을 WB 단계를 거치지 않고 바로 다음 명령어의 EX 단계 입력으로 '옆으로 전달'해주는 기술. 스톨을 방지하여 성능 저하를 크게 줄일 수 있음.

#### 3.2.3. 제어 해저드 (Control Hazard / Branch Hazard)
- 원인: if문이나 loop 같은 분기(branch) 명령어 때문에 발생. 분기 조건이 판별되기 전까지는 다음에 어떤 명령어를 가져와야 할지(IF 단계) 알 수 없음.
- 비유: 갈림길에서 '좌회전'할지 '우회전'할지 결정이 나기 전까지는 다음 길로 진입할 수 없는 상황. 파이프라인은 이미 다음 명령어를 가져오려고 하는데, 어디로 가야 할지 모르는 상황
- 해결책:
    - 파이프라인 스톨 (Stall): 분기 결과가 나올 때까지 파이프라인을 일단 중지.
    - 분기 예측 (Branch Prediction): (가장 중요하고 일반적인 해결책) 과거의 실행 기록을 바탕으로 이번에도 조건이 참(True)일거라 미리 예측하고, 예측한 경로의 명령어들을 파이프라인에 미리 채워 넣음
        - 예측 성공 시: 성능 저하 없이 파이프라인이 계속 흘러감
        - 예측 실패 시: 지금까지 파이프라인에 채워 넣었던 잘못된 명령어들을 모두 폐기(Flush)하고, 올바른 경로의 명령어부터 다시 채워야 하므로 상당한 성능 손실(penalty)이 발생

---

## 4. 고급 컴퓨터 구조
### 4.1. 명령어 수준 병렬 처리(Instruction-Level Parallelism, ILP)

ILP는 단일 CPU 코어 내에 여러 개의 실행 유닛(Execution Unit)을 두고, 서로 의존성이 없는 명령어들을 동시에 실행하여 성능을 높이는 모든 기술을 의미

#### 유능한 바리스타
- ILP가 없을 때: 바리스타 한 명이 커피 주문 하나를 받아, 원두를 갈고, 에스프레소를 내리고, 우유 스팀을 하고, 컵에 담는 모든 과정을 순서대로 끝내야 다음 주문을 받을 수 있음(1 클럭 = 1 명령어)
- ILP가 있을 때: 바리스타 한 명(단일 코어)이 동시에 여러 작업 수행. 에스프레소 머신이 샷을 내리는 동안(시간이 걸림), 옆에서는 우유 스팀을 준비하고, 다른 한 손으로는 컵을 준비(1 클럭 > 1 명령어)

ILP를 구현하는 대표적인 하드웨어 구조가 바로 파이프라이닝과 슈퍼스칼라

#### 4.1.1. ILP의 핵심 기술: 파이프라이닝
- 파이프라이닝: 하나의 명령어를 처리하는 과정을 여러 단계(예: 명령어 인출 → 해석 → 실행 → 결과 저장)로 나누고, 각 단계를 컨베이어 벨트처럼 동시에 처리하는 기술
- 한계: 파이프라이닝은 효율을 높이지만, 이상적인 상황에서도 1 클럭 당 최대 1개의 명령어를 완료시키는 것이 한계. 더 높은 성능을 위해서는 이 한계를 넘어야 함

#### 4.1.2. ILP의 핵심 기술: 슈퍼스칼라(Superscalar)
슈퍼스칼라는 파이프라인을 여러 개 갖춘 구조. 즉, 한 클럭에 여러 개의 명령어를 동시에 인출하고, 실행하고, 완료함

- 핵심 아이디어: CPU 내부에 ALU(정수 연산 장치), FPU(부동소수점 연산 장치) 등 여러 개의 독립적인 실행 유닛과 여러 개의 파이프라인을 배치
- 동작 방식 (동적 스케줄링):
    - CPU의 디코더(Decoder)가 한 번에 여러 개의 명령어를 읽어들임
    - 이 명령어들 사이의 의존성을 하드웨어가 실시간으로 분석
    - 서로 의존성이 없는 명령어들을 찾아내어, 놀고 있는 실행 유닛에 동시에 할당
- 비유: 바리스타(코어)에게 에스프레소 머신 2대, 우유 스티머 2대(여러 실행 유닛/파이프라인)가 주어지고, 아메리카노와 라떼 주문이 동시에 들어오면, 바리스타는 두 주문이 서로 상관없음을 인지하고, 한쪽 머신에서는 아메리카노의 샷을, 다른 쪽 머신에서는 라떼의 샷을 동시에 내림
- 특징: 이 모든 판단을 하드웨어(CPU)가 동적으로(실행 중에) 수행. 따라서 '똑똑한 하드웨어' 기술이라고 불림. 오늘날 우리가 사용하는 대부분의 고성용 CPU(Intel Core, AMD Ryzen, Apple M 시리즈 등)는 모두 슈퍼스칼라 구조 기반

#### 4.1.3. ILP를 가로막는 장애물: 의존성
커피 주문처럼 모든 명령어가 독립적일 수는 없음. ILP의 성능을 제한하는 주요 원인은 의존성

- 데이터 의존성 (Data Dependency): 앞선 명령어의 실행 결과가 다음 명령어의 입력 값으로 사용되는 경우

```
a = b + c;  // 이 계산이 끝나야
d = a * 2;  // a 값을 사용할 수 있음
```
- 
    - 해결책: 비순차적 실행(Out-of-Order Execution, OoOE) 같은 기술을 사용. CPU는 d = a * 2가 a의 결과를 기다리는 동안, 그 뒤에 있는 전혀 상관없는 명령어(ex. x = y + z)를 먼저 가져와 실행하여 노는 시간을 최소화시킴

- 제어 의존성 (Control Dependency): if문이나 loop 같은 분기(branch)문 때문에 발생. 분기문의 조건이 판별되기 전까지는 다음에 어떤 명령어를 실행해야 할지 알 수 없음
    - 해결책: 분기 예측(Branch Prediction) 기술 사용. CPU는 과거의 실행 패턴을 기반으로 '아마 이쪽으로 분기할 것이다'라고 예측하고, 그 경로의 명령어들을 미리 가져와 처리. 예측이 맞으면 성능이 크게 향상되고, 틀리면 지금까지 처리한 것을 모두 폐기하고 올바른 경로의 명령어를 다시 가져옴

### 4.2. 병렬 처리 및 멀티코어(Parallel Processing & Multicore)
ILP가 한 명의 일꾼을 더 빠르게 만드는 것이라면, 멀티코어 병렬 처리는 여러 명의 일꾼을 동시에 투입하는 방식

- 핵심 아이디어: 하나의 CPU 칩(프로세서) 안에 두 개 이상의 완전한 코어(Core)를 집적하는 기술. 운영체제(OS)는 각 코어를 별개의 CPU처럼 인식하고, 여러 스레드(Threads)나 프로세스를 각기 다른 코어에 할당하여 진정한 의미의 동시 작업을 수행. 이를 스레드 수준 병렬 처리(Thread-Level Parallelism, TLP)라고 함

- 캐시 일관성 문제 (Cache Coherency Problem): 멀티코어 구조에서 가장 중요하고 어려운 문제
    - 문제 상황: 코어 1이 자신의 L1 캐시에 있는 변수 `x`의 값을 10으로 바꿨다고 가정, 이때 코어 2의 L1 캐시에는 여전히 예전 값인 5가 남아있을 수 있음. 이 상태에서 코어 2가 `x`를 읽으면, 잘못된 데이터를 읽게 되어 프로그램 전체가 오작동
    - 해결책: 하드웨어 단에서 MESI 프로토콜과 같은 캐시 일관성 프로토콜을 사용하여, 한 코어의 캐시가 변경되면 다른 코어들에게 이 사실을 알리고 캐시 상태를 동기화
- 동기화 (Synchronization): 캐시 일관성 문제는 하드웨어가 해결해주지만, 여러 스레드가 공유된 데이터를 동시에 수정하려 할 때 발생하는 경쟁 상태(Race Condition)는 소프트웨어(프로그래머)가 해결해야함. 이를 위해 뮤텍스(Mutex), 세마포어(Semaphore), 원자적 연산(Atomic Operations)과 같은 동기화 기법을 사용

---

> 참고 링크
> https://nayoungs.tistory.com/entry/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B3%84%EC%B8%B5-%EA%B5%AC%EC%A1%B0Memory-Hierachy
